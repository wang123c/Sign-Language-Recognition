# Sign-Language-Recognition
This project focuses on sign language recognition based on a dual-channel Star-Attention Convolutional Neural Network (SACNN). Initially, the collected dataset undergoes preprocessing operations, including normalization and image size adjustment. Subsequently, the dataset is trained on a dual-channel Convolutional Neural Network (CNN). Different from other dual-channel approaches, the first channel in this study extracts gesture feature information, while the second channel extracts background features. By leveraging the Star-Attention mechanism, the gesture features are enhanced while the background features are weakened, thereby achieving effective gesture feature acquisition. This research aims to improve upon traditional dual-channel models to obtain a stable and economical SACNN model for gesture feature extraction. Through comparative experiments, the model demonstrates excellent generalization capabilities in sign language recognition.
First, run the dataset_split.py file to classify the dataset into training, validation, and test sets in ".txt" files. Subsequently, execute the to_pickle.py file to package the dataset into ".pickle" files. Finally, run the cnn_gen_picture_shape.py file to commence model training. The dataset is sourced from the Kaggle public dataset (ASL Finger Spelling Dataset): https://www.kaggle.com/datasets/mrgeislinger/asl-rgb-depth-fingerspelling-spelling-it-out.
